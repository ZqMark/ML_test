"""
函数功能：计算香浓熵
参数说明：
    dataSet:原始数据集
返回:
    ent:香浓熵的值
"""
def calEnt(dataSet):
    n = dataSet.shape[0]
    iset = dataSet.iloc[:,-1].value_counts()
    p= iset/n
    ent = (-p*np.log2(p)).sum()
    return ent
    #海洋生物数据
#创建数据集
import numpy as np
import pandas as pd
def creatDataSet():
    row_data={'no surfacing':[1,1,1,0,0],
             'flippers':[1,1,0,1,1],
             'fish':['yes','yes','no','no','no']}
    dataSet = pd.DataFrame(row_data)
    return dataSet
dataSet = creatDataSet()
print(dataSet)
# calEnt(dataSet)
"""
函数功能：根据信息增益选择出最佳数据集切分的列
参数说明：
    dataSet:原始数据集
返回：
    axis:数据集最佳切分列的索引
"""
#选择最优的列进行划分
def bestSplit(dataSet):
    baseEnt = calEnt(dataSet)
#     print(baseEnt)
    bestGain = 0

    for i in range(dataSet.shape[1]-1):
#         print(i)
        levels=dataSet.iloc[:,i].value_counts().index
        ents = 0
        for j in levels:
#             print(j)
            childSet = dataSet[dataSet.iloc[:,i]==j]   #每个子节点的dataframe
            ent = calEnt(childSet)
            ents += (childSet.shape[0]/dataSet.shape[0])*ent
        #print(f'第{i}列的信息熵为{ents}')
        infoGain = baseEnt-ents
#         print( infoGain)
        #print(f'第{i}列的信息增益为{infoGain}')
        if (infoGain > bestGain):
            bestGain = infoGain        #选择最大信息增益
            axis = i #最大信息增益所在的索引
#             print( bestGain )
#             print(axis)
    return axis
    """
函数功能:按照指定的列划分数据集
参数说明：
    dataSet:原始数据集
    axis:指定的列索引
    value:指定的属性值
返回:
   redataSet:按照指定列索引和属性切分后的数据集
"""
def mySplit(dataSet,axis,value):
    col = dataSet.columns[axis]
    redataSet = dataSet.loc[dataSet[col]==value,:].drop(col,axis=1)
    return redataSet
#编写代码构建决策树
"""
函数说明:基于最大信息增益切分数据集，递归构建决策树
参数说明:
    dataSet:原始数据集（最后一列是标签）
返回:
    myTree:字典形式的树
"""
def createTree(dataSet):
    featlist=list(dataSet.columns)
#     print(featlist)
    classlist=dataSet.iloc[:,-1].value_counts()
#     print(classlist)
#     print(classlist[0])
#     print(classlist.index[0])
    #判断最多标签数目是否等于数据集行数，或者数据集是否只有一列
    if classlist[0]==dataSet.shape[0] or dataSet.shape[1]==1:
        return classlist.index[0]
    axis = bestSplit(dataSet)
    bestfeat = featlist[axis]
#     print(bestfeat)
    myTree = {bestfeat:{}}
#     print(myTree)
    del featlist[axis]
#     print(featlist)
    valuelist = set(dataSet.iloc[:,axis])
#     print(valuelist)
    for value in valuelist:
        myTree[bestfeat][value]=createTree(mySplit(dataSet,axis,value))
#         print(myTree[bestfeat][value])
    return myTree 
    #决策树的存储
#树的存储
np.save('myTree.npy',myTree)
#树的读取
read_myTree = np.load('myTree.npy',allow_pickle=True).item()
read_myTree
#使用决策树执行分类
"""
函数功能：对一个测试实例进行分类
参数说明:
     inputTree:已经生成的决策树
     labels:存储选择的最优特征标签
     testVec:测试数据列表，顺序对应原数据集
返回：
   classLabel:分类结果
"""
def classify(inputTree,labels,testVec):
    firstStr = next(iter(inputTree))
    secondDict = inputTree[firstStr]
    featIndex = labels.index(firstStr)
    for key in secondDict.keys():
        if testVec[featIndex]==key:
            if type(secondDict[key])==dict:
                classLabel = classify(secondDict[key],labels,testVec)
            else:
                classLabel = secondDict[key]
    return classLabel
    """
函数功能：对测试集进行预测，并返回预测后的结果
参数说明:
    train:训练集
    test:测试集
返回:
   test:预测好分类的测试集
"""
def acc_classify(train,test):
    inputTree=createTree(train)
    labels = list(train.columns)
    result = []
    for i in range(test.shape[0]):
        testVec = test.iloc[i,:-1]
        classLabel = classify(inputTree,labels,testVec)
        result.append(classLabel)
    test['predict']=result
    acc = (test.iloc[:,-1]==test.iloc[:,-2]).mean()   #计算准确率
    print(f'模型预测准确率为{acc}')
    return test
#测试数据
train = dataSet
test = dataSet.iloc[:3,:]
acc_classify(train,test)
#使用sklearn 中的graphviz包实现决策树的绘制
#导入相应的包
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
import graphviz
#特征
Xtrain = dataSet.iloc[:,:-1]
#标签
Ytrain = dataSet.iloc[:,-1]
labels = Ytrain.unique().tolist()
print(labels)
Ytrain = Ytrain.apply(lambda x: labels.index(x)) #将文本转化为数字

#绘制数模型
clf = DecisionTreeClassifier()
clf = clf.fit(Xtrain,Ytrain)
tree.export_graphviz(clf)
dot_data = tree.export_graphviz(clf,out_file=None)
graphviz.Source(dot_data)

